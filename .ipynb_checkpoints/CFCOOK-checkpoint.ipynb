{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import scipy\n",
    "from collections import defaultdict\n",
    "from surprise import SVD, Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import csv\n",
    "import numpy as np\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"C:/Users/云舒/21Fall/CSE258/HW3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    c = csv.reader(f)\n",
    "    header = next(c)\n",
    "    for l in c:\n",
    "        d = dict(zip(header,l))\n",
    "        yield d['user_id'],d['recipe_id'],d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "userIDs = []\n",
    "itemIDs = []\n",
    "\n",
    "for user,recipe,d in readCSV(\"trainInteractions.csv.gz\"):\n",
    "    userIDs.append(user)\n",
    "    itemIDs.append(recipe)\n",
    "    r = int(d['rating'])\n",
    "    allRatings.append(r)\n",
    "    userRatings[user].append(r)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "  userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "itemRatings = defaultdict(list)\n",
    "\n",
    "for user,recipe,d in readCSV(\"trainInteractions.csv.gz\"):\n",
    "    r = int(d['rating'])\n",
    "    allRatings.append(r)\n",
    "    userRatings[user].append(r)\n",
    "    itemRatings[recipe].append(r)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "\n",
    "userAverage = {}\n",
    "itemAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "for i in itemRatings:\n",
    "    itemAverage[i] = sum(itemRatings[i])/len(itemRatings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item timestamp rating', sep=',',skip_lines=1)\n",
    "data = Dataset.load_from_file(dataDir + \"trainInteractions.csv\", reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.9776  0.9792  0.9858  0.9809  0.0036  \n",
      "MAE (testset)     0.5676  0.5674  0.5698  0.5683  0.0011  \n",
      "Fit time          13.30   14.44   10.38   12.71   1.71    \n",
      "Test time         6.85    9.44    6.86    7.72    1.22    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.97757714, 0.97917645, 0.98583105]),\n",
       " 'test_mae': array([0.5676291 , 0.56741147, 0.56976552]),\n",
       " 'fit_time': (13.303996086120605, 14.440507411956787, 10.375757455825806),\n",
       " 'test_time': (6.852864027023315, 9.443424224853516, 6.862478494644165)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = KNNWithMeans()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rated.txt\", 'w')\n",
    "for l in open(\"stub_Rated.txt\"):\n",
    "    if l.startswith(\"user_id\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    if u in userIDs and i in itemIDs:\n",
    "        r = algo.predict(u,i).est\n",
    "    elif u in userIDs:\n",
    "        r = userAverage[u]\n",
    "    elif i in itemIDs:\n",
    "        r = itemAverage[i]\n",
    "    else:\n",
    "        r = -1\n",
    "        \n",
    "    if r >= globalAverage*k : \n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "        \n",
    "    \n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
